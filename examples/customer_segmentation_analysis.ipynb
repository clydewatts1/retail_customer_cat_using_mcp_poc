{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa1986b",
   "metadata": {},
   "source": [
    "# Customer Segmentation Analysis\n",
    "## Clustering and Visualization with Hierarchical Department/Class Structure\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Generating synthetic retail customer data with hierarchical product structure\n",
    "- Applying Fuzzy C-Means clustering\n",
    "- Applying Neural Network clustering\n",
    "- Visualizing customer segments and their characteristics\n",
    "- Analyzing department, class, and size preferences by segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99b885",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d739a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Custom modules\n",
    "from customer_segmentation import RetailDataGenerator, get_config\n",
    "from customer_segmentation.fuzzy_clustering import FuzzyCustomerSegmentation\n",
    "from customer_segmentation.neural_clustering import NeuralCustomerSegmentation\n",
    "from customer_segmentation.cluster_enrichment import ClusterEnrichment\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a37e3",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Generate Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = get_config()\n",
    "print(f\"Configuration loaded from: {config.config_path}\")\n",
    "\n",
    "# Initialize data generator\n",
    "generator = RetailDataGenerator(seed=config.data_generation.random_seed)\n",
    "\n",
    "# Generate customer data with hierarchical department/class structure\n",
    "data = generator.generate_customers(\n",
    "    n_customers=config.data_generation.n_customers,\n",
    "    segment_probs=list(config.data_generation.segment_probabilities.values())\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Generated {len(data)} customer records\")\n",
    "print(f\"Features ({len(data.columns)}): {list(data.columns)}\")\n",
    "print(f\"\\nData shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea05419",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"=== Basic Statistics ===\")\n",
    "core_features = ['total_purchases', 'total_revenue', 'avg_order_value', \n",
    "                 'recency_days', 'frequency_per_month', 'customer_lifetime_months', 'return_rate']\n",
    "data[core_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64368e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RFM distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('RFM Feature Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot distributions\n",
    "features_to_plot = ['total_revenue', 'frequency_per_month', 'recency_days', \n",
    "                    'avg_order_value', 'total_purchases', 'return_rate']\n",
    "\n",
    "for idx, feature in enumerate(features_to_plot):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    axes[row, col].hist(data[feature], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[row, col].set_title(feature.replace('_', ' ').title())\n",
    "    axes[row, col].set_xlabel('Value')\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize department and class distributions\n",
    "dept_cols = [col for col in data.columns if col.startswith('dept_total_value_')]\n",
    "class_cols = [col for col in data.columns if col.startswith('class_total_value_')]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Department totals\n",
    "dept_totals = data[dept_cols].sum()\n",
    "axes[0].bar(range(len(dept_totals)), dept_totals.values, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xticks(range(len(dept_totals)))\n",
    "axes[0].set_xticklabels([col.replace('dept_total_value_', '') for col in dept_cols], rotation=45, ha='right')\n",
    "axes[0].set_title('Total Sales by Department', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Total Value ($)')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Class totals\n",
    "class_totals = data[class_cols].sum()\n",
    "axes[1].bar(range(len(class_totals)), class_totals.values, color='coral', edgecolor='black')\n",
    "axes[1].set_xticks(range(len(class_totals)))\n",
    "axes[1].set_xticklabels([col.replace('class_total_value_', '') for col in class_cols], rotation=45, ha='right')\n",
    "axes[1].set_title('Total Sales by Class', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Total Value ($)')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dadfb",
   "metadata": {},
   "source": [
    "## 4. Fuzzy C-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Fuzzy C-Means clustering\n",
    "fuzzy_config = config.to_dict()['fuzzy_clustering']\n",
    "fuzzy_model = FuzzyCustomerSegmentation(\n",
    "    n_clusters=fuzzy_config['n_clusters'],\n",
    "    m=fuzzy_config['fuzziness_parameter'],\n",
    "    max_iter=fuzzy_config['max_iterations'],\n",
    "    error=fuzzy_config['tolerance'],\n",
    "    seed=fuzzy_config['random_seed']\n",
    ")\n",
    "\n",
    "# Store config for feature selection\n",
    "fuzzy_model.config = config.to_dict()\n",
    "\n",
    "# Fit and predict\n",
    "print(\"Fitting Fuzzy C-Means clustering...\")\n",
    "fuzzy_labels, fuzzy_membership = fuzzy_model.fit_predict(data)\n",
    "\n",
    "# Add results to dataframe\n",
    "data['fuzzy_cluster'] = fuzzy_labels\n",
    "\n",
    "# Display cluster distribution\n",
    "print(f\"\\n✓ Fuzzy clustering completed with {fuzzy_config['n_clusters']} clusters\")\n",
    "print(\"\\nCluster distribution:\")\n",
    "print(data['fuzzy_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Calculate metrics\n",
    "fuzzy_metrics = fuzzy_model.evaluate(data)\n",
    "print(f\"\\nFuzzy Clustering Metrics:\")\n",
    "for metric, value in fuzzy_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cluster centers\n",
    "cluster_centers_df = fuzzy_model.get_cluster_centers()\n",
    "print(\"\\n=== Fuzzy Cluster Centers ===\")\n",
    "cluster_centers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f01cb3",
   "metadata": {},
   "source": [
    "## 5. Neural Network Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403001d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Neural Network clustering\n",
    "neural_config = config.to_dict()['neural_clustering']\n",
    "neural_model = NeuralCustomerSegmentation(\n",
    "    n_clusters=neural_config['n_clusters'],\n",
    "    encoding_dim=neural_config['encoding_dim'],\n",
    "    epochs=neural_config['epochs'],\n",
    "    batch_size=neural_config['batch_size'],\n",
    "    seed=neural_config['random_seed']\n",
    ")\n",
    "\n",
    "# Store config for feature selection\n",
    "neural_model.config = config.to_dict()\n",
    "\n",
    "# Fit and predict\n",
    "print(\"Training Neural Network clustering (this may take a moment)...\")\n",
    "neural_labels = neural_model.fit_predict(data, verbose=0)\n",
    "\n",
    "# Add results to dataframe\n",
    "data['neural_cluster'] = neural_labels\n",
    "\n",
    "# Display cluster distribution\n",
    "print(f\"\\n✓ Neural clustering completed with {neural_config['n_clusters']} clusters\")\n",
    "print(\"\\nCluster distribution:\")\n",
    "print(data['neural_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Calculate metrics\n",
    "neural_metrics = neural_model.evaluate(data)\n",
    "print(f\"\\nNeural Clustering Metrics:\")\n",
    "for metric, value in neural_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eef544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display neural cluster centers\n",
    "neural_centers_df = neural_model.get_cluster_centers()\n",
    "print(\"\\n=== Neural Cluster Centers ===\")\n",
    "neural_centers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55b439",
   "metadata": {},
   "source": [
    "## 5.5 Gaussian Mixture Models (GMM) Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99240ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize GMM clustering\n",
    "gmm_config = config.to_dict()['fuzzy_clustering']  # Use same config for n_clusters\n",
    "n_clusters_gmm = gmm_config['n_clusters']\n",
    "\n",
    "# Prepare features for GMM (using enriched features if enabled)\n",
    "if gmm_config.get('use_enriched_features', False):\n",
    "    feature_cols_gmm = gmm_config['features_to_use'] + gmm_config['enriched_features_to_use']\n",
    "else:\n",
    "    feature_cols_gmm = gmm_config['features_to_use']\n",
    "\n",
    "feature_cols_gmm = [col for col in feature_cols_gmm if col in data.columns]\n",
    "\n",
    "# Standardize features\n",
    "scaler_gmm = StandardScaler()\n",
    "X_gmm = data[feature_cols_gmm].values\n",
    "X_gmm_normalized = scaler_gmm.fit_transform(X_gmm)\n",
    "\n",
    "# Fit Gaussian Mixture Model\n",
    "print(f\"Fitting Gaussian Mixture Model with {n_clusters_gmm} components...\")\n",
    "gmm_model = GaussianMixture(\n",
    "    n_components=n_clusters_gmm,\n",
    "    covariance_type='full',  # Full covariance matrix\n",
    "    random_state=gmm_config['random_seed'],\n",
    "    max_iter=200,\n",
    "    n_init=10\n",
    ")\n",
    "\n",
    "# Fit and predict\n",
    "gmm_labels = gmm_model.fit_predict(X_gmm_normalized)\n",
    "gmm_proba = gmm_model.predict_proba(X_gmm_normalized)\n",
    "\n",
    "# Add results to dataframe\n",
    "data['gmm_cluster'] = gmm_labels\n",
    "\n",
    "# Display cluster distribution\n",
    "print(f\"\\n✓ GMM clustering completed with {n_clusters_gmm} components\")\n",
    "print(f\"Converged: {gmm_model.converged_}\")\n",
    "print(f\"Number of iterations: {gmm_model.n_iter_}\")\n",
    "print(\"\\nCluster distribution:\")\n",
    "print(data['gmm_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "gmm_silhouette = silhouette_score(X_gmm_normalized, gmm_labels)\n",
    "gmm_bic = gmm_model.bic(X_gmm_normalized)\n",
    "gmm_aic = gmm_model.aic(X_gmm_normalized)\n",
    "gmm_davies_bouldin = davies_bouldin_score(X_gmm_normalized, gmm_labels)\n",
    "gmm_calinski = calinski_harabasz_score(X_gmm_normalized, gmm_labels)\n",
    "\n",
    "gmm_metrics = {\n",
    "    'silhouette_score': gmm_silhouette,\n",
    "    'bic': gmm_bic,\n",
    "    'aic': gmm_aic,\n",
    "    'davies_bouldin_index': gmm_davies_bouldin,\n",
    "    'calinski_harabasz_score': gmm_calinski,\n",
    "    'log_likelihood': gmm_model.score(X_gmm_normalized) * len(X_gmm_normalized),\n",
    "    'n_clusters': float(n_clusters_gmm)\n",
    "}\n",
    "\n",
    "print(f\"\\nGMM Clustering Metrics:\")\n",
    "for metric, value in gmm_metrics.items():\n",
    "    if metric in ['bic', 'aic', 'log_likelihood', 'calinski_harabasz_score']:\n",
    "        print(f\"  {metric}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GMM cluster centers (means)\n",
    "gmm_centers = pd.DataFrame(\n",
    "    scaler_gmm.inverse_transform(gmm_model.means_),\n",
    "    columns=feature_cols_gmm\n",
    ")\n",
    "gmm_centers.index = [f'Cluster_{i}' for i in range(n_clusters_gmm)]\n",
    "\n",
    "print(\"\\n=== GMM Cluster Centers (Means) ===\")\n",
    "# Show core features only for readability\n",
    "core_features_display = [col for col in gmm_centers.columns if col in core_features]\n",
    "gmm_centers[core_features_display]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GMM cluster probabilities (soft assignments)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# GMM hard clustering\n",
    "scatter1 = axes[0].scatter(data['recency_days'], data['total_revenue'], \n",
    "                           c=data['gmm_cluster'], cmap='viridis', \n",
    "                           alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Recency (days)', fontsize=12)\n",
    "axes[0].set_ylabel('Total Revenue ($)', fontsize=12)\n",
    "axes[0].set_title('GMM Clustering (Hard Assignment)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# GMM soft clustering - show maximum probability\n",
    "max_proba = gmm_proba.max(axis=1)\n",
    "scatter2 = axes[1].scatter(data['recency_days'], data['total_revenue'], \n",
    "                           c=max_proba, cmap='plasma', \n",
    "                           alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Recency (days)', fontsize=12)\n",
    "axes[1].set_ylabel('Total Revenue ($)', fontsize=12)\n",
    "axes[1].set_title('GMM Clustering (Assignment Confidence)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Max Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GMM probability matrix (sample of customers)\n",
    "sample_size = min(50, len(data))\n",
    "sample_indices = np.random.choice(len(data), sample_size, replace=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(gmm_proba[sample_indices], \n",
    "            annot=False, \n",
    "            cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Probability'},\n",
    "            xticklabels=[f'Cluster {i}' for i in range(n_clusters_gmm)],\n",
    "            yticklabels=[f'Customer {i}' for i in sample_indices[:20]] + ['...'] * (sample_size - 20) if sample_size > 20 else [f'Customer {i}' for i in sample_indices])\n",
    "\n",
    "plt.title(f'GMM Cluster Membership Probabilities (Sample of {sample_size} Customers)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Customer', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show statistics about cluster assignment confidence\n",
    "avg_max_proba = gmm_proba.max(axis=1).mean()\n",
    "print(f\"\\nGMM Assignment Confidence Statistics:\")\n",
    "print(f\"  Average maximum probability: {avg_max_proba:.4f}\")\n",
    "print(f\"  Customers with >90% confidence: {(gmm_proba.max(axis=1) > 0.9).sum()} ({(gmm_proba.max(axis=1) > 0.9).sum()/len(data)*100:.1f}%)\")\n",
    "print(f\"  Customers with <70% confidence: {(gmm_proba.max(axis=1) < 0.7).sum()} ({(gmm_proba.max(axis=1) < 0.7).sum()/len(data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40dfab",
   "metadata": {},
   "source": [
    "## 6. Cluster Enrichment and Segment Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d461ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich fuzzy clusters with meaningful descriptions\n",
    "enricher = ClusterEnrichment()\n",
    "enriched_segments = enricher.enrich_clusters(data, 'neural_cluster')\n",
    "\n",
    "print(f\"✓ Enriched {len(enriched_segments)} cluster profiles\\n\")\n",
    "\n",
    "# Display segment summaries\n",
    "for segment in enriched_segments:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Cluster {segment['cluster_id']}: {segment['segment_name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nDescription: {segment['description']}\")\n",
    "    print(f\"\\nKey Characteristics:\")\n",
    "    print(f\"  - Segment Size: {segment['size']} customers ({segment['percentage']:.1f}%)\")\n",
    "    print(f\"  - Avg Revenue: ${segment['avg_revenue']:,.2f}\")\n",
    "    print(f\"  - Avg Order Value: ${segment['avg_order_value']:.2f}\")\n",
    "    print(f\"  - Avg Frequency: {segment['avg_frequency']:.2f} purchases/month\")\n",
    "    print(f\"  - Avg Recency: {segment['avg_recency']:.0f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba094f6d",
   "metadata": {},
   "source": [
    "## 7. Visualize Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd366b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM scatter plot with all three clustering methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Fuzzy clustering\n",
    "scatter1 = axes[0].scatter(data['recency_days'], data['total_revenue'], \n",
    "                           c=data['fuzzy_cluster'], cmap='viridis', \n",
    "                           alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Recency (days)', fontsize=12)\n",
    "axes[0].set_ylabel('Total Revenue ($)', fontsize=12)\n",
    "axes[0].set_title('Fuzzy C-Means Clustering', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# Neural clustering\n",
    "scatter2 = axes[1].scatter(data['recency_days'], data['total_revenue'], \n",
    "                           c=data['neural_cluster'], cmap='viridis', \n",
    "                           alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Recency (days)', fontsize=12)\n",
    "axes[1].set_ylabel('Total Revenue ($)', fontsize=12)\n",
    "axes[1].set_title('Neural Network Clustering', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "\n",
    "# GMM clustering\n",
    "scatter3 = axes[2].scatter(data['recency_days'], data['total_revenue'], \n",
    "                           c=data['gmm_cluster'], cmap='viridis', \n",
    "                           alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "axes[2].set_xlabel('Recency (days)', fontsize=12)\n",
    "axes[2].set_ylabel('Total Revenue ($)', fontsize=12)\n",
    "axes[2].set_title('GMM Clustering', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(alpha=0.3)\n",
    "plt.colorbar(scatter3, ax=axes[2], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster size comparison - all three methods\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Fuzzy cluster distribution\n",
    "fuzzy_counts = data['fuzzy_cluster'].value_counts().sort_index()\n",
    "axes[0].bar(fuzzy_counts.index, fuzzy_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Cluster', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Customers', fontsize=12)\n",
    "axes[0].set_title('Fuzzy C-Means - Cluster Sizes', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(fuzzy_counts.values):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Neural cluster distribution\n",
    "neural_counts = data['neural_cluster'].value_counts().sort_index()\n",
    "axes[1].bar(neural_counts.index, neural_counts.values, color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('Cluster', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Customers', fontsize=12)\n",
    "axes[1].set_title('Neural Network - Cluster Sizes', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(neural_counts.values):\n",
    "    axes[1].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# GMM cluster distribution\n",
    "gmm_counts = data['gmm_cluster'].value_counts().sort_index()\n",
    "axes[2].bar(gmm_counts.index, gmm_counts.values, color='mediumseagreen', edgecolor='black')\n",
    "axes[2].set_xlabel('Cluster', fontsize=12)\n",
    "axes[2].set_ylabel('Number of Customers', fontsize=12)\n",
    "axes[2].set_title('GMM - Cluster Sizes', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(gmm_counts.values):\n",
    "    axes[2].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98071a",
   "metadata": {},
   "source": [
    "## 8. Department and Class Preferences by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department preferences by cluster (using neural clusters)\n",
    "dept_cols = [col for col in data.columns if col.startswith('dept_total_value_')]\n",
    "dept_by_cluster = data.groupby('neural_cluster')[dept_cols].mean()\n",
    "\n",
    "# Rename columns for better display\n",
    "dept_by_cluster.columns = [col.replace('dept_total_value_', '') for col in dept_by_cluster.columns]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(dept_by_cluster.T, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Average Value ($)'}, linewidths=0.5)\n",
    "plt.title('Department Preferences by Cluster (Neural Clustering)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Department', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class preferences by cluster (using neural clusters)\n",
    "class_cols = [col for col in data.columns if col.startswith('class_total_value_')]\n",
    "class_by_cluster = data.groupby('neural_cluster')[class_cols].mean()\n",
    "\n",
    "# Rename columns for better display\n",
    "class_by_cluster.columns = [col.replace('class_total_value_', '') for col in class_by_cluster.columns]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.heatmap(class_by_cluster.T, annot=True, fmt='.0f', cmap='Blues', \n",
    "            cbar_kws={'label': 'Average Value ($)'}, linewidths=0.5)\n",
    "plt.title('Class Preferences by Cluster (Neural Clustering)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('Class', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c718e12",
   "metadata": {},
   "source": [
    "## 9. Size Distribution by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size distribution by cluster\n",
    "size_cols = [col for col in data.columns if col.startswith('count_size_') or col in ['count_Baby', 'count_Child']]\n",
    "size_by_cluster = data.groupby('neural_cluster')[size_cols].mean()\n",
    "\n",
    "# Rename columns for better display\n",
    "size_by_cluster.columns = [col.replace('count_size_', '').replace('count_', '') for col in size_by_cluster.columns]\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(size_by_cluster.columns))\n",
    "width = 0.2\n",
    "\n",
    "for i, cluster in enumerate(size_by_cluster.index):\n",
    "    offset = width * (i - len(size_by_cluster.index) / 2)\n",
    "    ax.bar(x + offset, size_by_cluster.iloc[i], width, \n",
    "           label=f'Cluster {cluster}', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Size/Age Category', fontsize=12)\n",
    "ax.set_ylabel('Average Count', fontsize=12)\n",
    "ax.set_title('Size/Age Distribution by Cluster (Neural Clustering)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(size_by_cluster.columns, rotation=0)\n",
    "ax.legend(title='Cluster', fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b60d59",
   "metadata": {},
   "source": [
    "## 10. Cluster Characteristics Radar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa7511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radar chart for cluster characteristics\n",
    "from math import pi\n",
    "\n",
    "# Select features for radar chart\n",
    "features = ['total_revenue', 'frequency_per_month', 'avg_order_value', 'return_rate']\n",
    "cluster_stats = data.groupby('neural_cluster')[features].mean()\n",
    "\n",
    "# Normalize to 0-1 scale for better visualization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "cluster_stats_normalized = pd.DataFrame(\n",
    "    scaler.fit_transform(cluster_stats),\n",
    "    columns=cluster_stats.columns,\n",
    "    index=cluster_stats.index\n",
    ")\n",
    "\n",
    "# Number of variables\n",
    "num_vars = len(features)\n",
    "angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "for cluster in cluster_stats_normalized.index:\n",
    "    values = cluster_stats_normalized.loc[cluster].values.tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=f'Cluster {cluster}')\n",
    "    ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels([f.replace('_', ' ').title() for f in features], size=11)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Cluster Characteristics (Normalized)', size=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0310a",
   "metadata": {},
   "source": [
    "## 11. Compare Clustering Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three clustering methods\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': ['Fuzzy C-Means', 'Neural Network', 'Gaussian Mixture'],\n",
    "    'Silhouette Score': [\n",
    "        fuzzy_metrics['silhouette_score'], \n",
    "        neural_metrics['silhouette_score'],\n",
    "        gmm_metrics['silhouette_score']\n",
    "    ],\n",
    "    'Clusters': [\n",
    "        fuzzy_config['n_clusters'], \n",
    "        neural_config['n_clusters'],\n",
    "        gmm_metrics['n_clusters']\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Add method-specific metrics\n",
    "comparison_df['Method Specific Metric'] = [\n",
    "    f\"Partition Coeff: {fuzzy_metrics['partition_coefficient']:.4f}\",\n",
    "    f\"Reconstruction Error: {neural_metrics['reconstruction_error']:.4f}\",\n",
    "    f\"BIC: {gmm_metrics['bic']:.2f}\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== Clustering Methods Comparison ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Silhouette Score comparison\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.5\n",
    "\n",
    "bars = axes[0].bar(x, comparison_df['Silhouette Score'], width, \n",
    "                   color=['steelblue', 'coral', 'mediumseagreen'], \n",
    "                   edgecolor='black', linewidth=1.5)\n",
    "\n",
    "axes[0].set_xlabel('Clustering Method', fontsize=12)\n",
    "axes[0].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[0].set_title('Clustering Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(comparison_df['Method'], rotation=15, ha='right')\n",
    "axes[0].set_ylim(0, max(comparison_df['Silhouette Score']) * 1.2)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Additional metrics comparison\n",
    "metrics_data = {\n",
    "    'Fuzzy': [fuzzy_metrics['partition_coefficient']],\n",
    "    'Neural': [neural_metrics['reconstruction_error']],\n",
    "    'GMM': [gmm_metrics['davies_bouldin_index']]\n",
    "}\n",
    "\n",
    "x2 = np.arange(3)\n",
    "axes[1].bar(0, fuzzy_metrics['partition_coefficient'], width, \n",
    "            color='steelblue', edgecolor='black', label='Partition Coefficient')\n",
    "axes[1].bar(1, neural_metrics['reconstruction_error'], width, \n",
    "            color='coral', edgecolor='black', label='Reconstruction Error')\n",
    "axes[1].bar(2, gmm_metrics['davies_bouldin_index'], width, \n",
    "            color='mediumseagreen', edgecolor='black', label='Davies-Bouldin Index')\n",
    "\n",
    "axes[1].set_xlabel('Clustering Method', fontsize=12)\n",
    "axes[1].set_ylabel('Metric Value', fontsize=12)\n",
    "axes[1].set_title('Method-Specific Metrics', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x2)\n",
    "axes[1].set_xticklabels(['Fuzzy C-Means', 'Neural Network', 'GMM'], rotation=15, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\n=== Detailed Metrics Comparison ===\")\n",
    "print(f\"\\nFuzzy C-Means:\")\n",
    "print(f\"  Silhouette Score: {fuzzy_metrics['silhouette_score']:.4f}\")\n",
    "print(f\"  Partition Coefficient: {fuzzy_metrics['partition_coefficient']:.4f}\")\n",
    "print(f\"  Partition Entropy: {fuzzy_metrics['partition_entropy']:.4f}\")\n",
    "\n",
    "print(f\"\\nNeural Network:\")\n",
    "print(f\"  Silhouette Score: {neural_metrics['silhouette_score']:.4f}\")\n",
    "print(f\"  Reconstruction Error: {neural_metrics['reconstruction_error']:.4f}\")\n",
    "\n",
    "print(f\"\\nGaussian Mixture Model:\")\n",
    "print(f\"  Silhouette Score: {gmm_metrics['silhouette_score']:.4f}\")\n",
    "print(f\"  BIC: {gmm_metrics['bic']:.2f}\")\n",
    "print(f\"  AIC: {gmm_metrics['aic']:.2f}\")\n",
    "print(f\"  Davies-Bouldin Index: {gmm_metrics['davies_bouldin_index']:.4f} (lower is better)\")\n",
    "print(f\"  Calinski-Harabasz Score: {gmm_metrics['calinski_harabasz_score']:.2f} (higher is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e832e14",
   "metadata": {},
   "source": [
    "## 12. Summary and Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5374ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CUSTOMER SEGMENTATION ANALYSIS - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n📊 Data Overview:\")\n",
    "print(f\"  - Total Customers: {len(data)}\")\n",
    "print(f\"  - Total Features: {len(data.columns)}\")\n",
    "print(f\"  - Hierarchical Structure: Departments → Classes\")\n",
    "\n",
    "print(f\"\\n🎯 Clustering Results:\")\n",
    "print(f\"  - Fuzzy C-Means:\")\n",
    "print(f\"    • Clusters: {fuzzy_config['n_clusters']}\")\n",
    "print(f\"    • Silhouette Score: {fuzzy_metrics['silhouette_score']:.4f}\")\n",
    "print(f\"    • Partition Coefficient: {fuzzy_metrics['partition_coefficient']:.4f}\")\n",
    "\n",
    "print(f\"\\n  - Neural Network:\")\n",
    "print(f\"    • Clusters: {neural_config['n_clusters']}\")\n",
    "print(f\"    • Silhouette Score: {neural_metrics['silhouette_score']:.4f}\")\n",
    "print(f\"    • Reconstruction Error: {neural_metrics['reconstruction_error']:.4f}\")\n",
    "\n",
    "print(f\"\\n  - Gaussian Mixture Model:\")\n",
    "print(f\"    • Clusters: {int(gmm_metrics['n_clusters'])}\")\n",
    "print(f\"    • Silhouette Score: {gmm_metrics['silhouette_score']:.4f}\")\n",
    "print(f\"    • BIC: {gmm_metrics['bic']:.2f}\")\n",
    "print(f\"    • Davies-Bouldin Index: {gmm_metrics['davies_bouldin_index']:.4f}\")\n",
    "\n",
    "print(f\"\\n💡 Key Insights:\")\n",
    "print(f\"  - All three methods identified {fuzzy_config['n_clusters']} distinct customer segments\")\n",
    "print(f\"  - Clusters show clear patterns in department/class preferences\")\n",
    "print(f\"  - Size/age distributions vary significantly across segments\")\n",
    "print(f\"  - Hierarchical product structure enables detailed preference analysis\")\n",
    "print(f\"  - GMM provides probabilistic cluster assignments (soft clustering)\")\n",
    "print(f\"  - Different methods capture different aspects of customer behavior\")\n",
    "\n",
    "print(f\"\\n🏆 Best Performing Method:\")\n",
    "silhouette_scores = {\n",
    "    'Fuzzy C-Means': fuzzy_metrics['silhouette_score'],\n",
    "    'Neural Network': neural_metrics['silhouette_score'],\n",
    "    'GMM': gmm_metrics['silhouette_score']\n",
    "}\n",
    "best_method = max(silhouette_scores, key=silhouette_scores.get)\n",
    "print(f\"  - {best_method} (Silhouette Score: {silhouette_scores[best_method]:.4f})\")\n",
    "\n",
    "print(f\"\\n📈 Next Steps:\")\n",
    "print(f\"  - Apply findings to marketing campaign targeting\")\n",
    "print(f\"  - Develop personalized product recommendations\")\n",
    "print(f\"  - Monitor segment migration over time\")\n",
    "print(f\"  - Integrate with AI agents for automated customer interactions\")\n",
    "print(f\"  - Use GMM probabilities for customer uncertainty analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
